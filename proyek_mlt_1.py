# -*- coding: utf-8 -*-
"""proyek_mlt_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GDFqIXca88QjrRD_1gKlb6cPKWCV9ykf

# **Predictive Analytics Energy Consumption**

#Import Library
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

"""# Data Loading"""

train_url = 'https://raw.githubusercontent.com/abdul-rar/proyek_mlt_1/refs/heads/main/dataset/train_energy_data.csv'
train_data = pd.read_csv(train_url)
train_data.head(10)

test_url = 'https://raw.githubusercontent.com/abdul-rar/proyek_mlt_1/refs/heads/main/dataset/test_energy_data.csv'
test_data = pd.read_csv(test_url)
test_data.head(10)

combined_df = pd.concat([train_data, test_data], axis=0).reset_index(drop=True)
combined_df.head()

"""# Exploratory Data Analysis (EDA)

## Deskripsi Variabel

Berdasarkan informasi dari sumber dataset, yaitu kaggle, variabel-variabel pada energy consumption dataset adalah:

- Building Type: fitur kategorikal yang merepresentasikan tipe bangunan
- Square Footage: fitur numerikan yang merepresentasikan luas bangunan dalam kaki(feet) persegi
- Number of Occupants: fitur numerik yang mengindikasikan berapa orang yang menempati bangunan tersebut
- Appliance Used: fitur numerik yang menunjukan berapa perangkat atau peralatan yang membutuhkan energi pada bangunan
- Average Temprature: fitur numerik yang menunjukan rata-rata teperatur atau suhu dari bangunan atau area iklim dengan satuan celcius
- Day of Week: fitur karegorik yang merepresentasikan data diambil pada weekend atau weekday
- Energy Consumption: fitur target berupa numerik yang merepresentasikan konsumsi energi dari bangunan dalam kWh (kilowatt-hours)

## Cek Value dan Data Cleaning

Pada tahap ini dilakukan pengecekan apakah ada missing value, duplicate, outlier, dan ketidaksesuaian tipe data
"""

combined_df.info()

combined_df.describe()

combined_df.duplicated().sum()

"""Pada dataset tidak ada missing value dan duplicate. Selanjutnya cek outlier"""

# Pilih fitur numerik
numeric_cols = ['Square Footage', 'Number of Occupants', 'Appliances Used', 'Average Temperature']

# Ukuran plot
plt.figure(figsize=(15, 10))

# Loop dan buat boxplot
for i, feature in enumerate(numeric_cols):
    plt.subplot(3, 3, i+1)
    sns.boxplot(x=combined_df[feature])
    plt.title(f'Boxplot of {feature}')

plt.tight_layout()
plt.show()

"""Tidak ada outliers juga pada data

## Univariate Analysis

Pada bagian ini akan menganalisis setiap fitur pada dataset secara satu persatu
"""

numerical_features = ['Square Footage', 'Number of Occupants', 'Appliances Used', 'Average Temperature', 'Energy Consumption']
categorical_features = ['Building Type', 'Day of Week']

"""### Categorical Features"""

#Fitur Building Type
feature = categorical_features[0]
count = combined_df[feature].value_counts()
percent = 100*combined_df[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

#Fitur Day of Week
feature = categorical_features[1]
count = combined_df[feature].value_counts()
percent = 100*combined_df[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Kedua fitur memiliki distribusi yang merata untuk setiap value nya,
- Redidential, Commercial, dan Industrial memiliki distribusi yang hampir merata
- Weekday dan Weekend memiliki distribusi yang hampir merata

### Numerical Features
"""

combined_df.hist(bins=50, figsize=(20,15))
plt.show()

"""- Energy consumption memiliki distribusi yang hampir normal dengan nilai energy consumption yang ditengah-tengah memiliki sample yang banyak
- Energy consumption yang rendah dan tinggi memiliki sample yang sedikit
- Fitur lain memiliki distribusi yang beragam atau tidak mengikuti pola tertentu

## Multivariate Analysis

Menganalisis beberapa fitur atau untuk mengetahui hubungan antar fitur di dataset
"""

# Fitur Kategorikal
for col in categorical_features:
  sns.catplot(x=col, y="Energy Consumption", kind="bar", dodge=False, height = 4, aspect = 3,  data=combined_df, palette="Set3")
  plt.title("Rata-rata 'price' Relatif terhadap - {}".format(col))

"""- Pada fitur "Type of Building", rata-rata energy consumption memiliki rentang diantara 3700 - 4700, dengan residential paling kecil, disusul oleh commercial, lalu industrial
- Pada fitur "Day of Week", rata-rata energy consumption memiliki nilai yang mirip, bahkan hampir sama untuk kedua jenis hari
- Dapat disimpulkan bahwa fitur "Type of Building" memiliki pengaruh yang kecil ke energy consumption sedangkan fitur "Day of Week" hampir tidak memiliki pengaruh
"""

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(combined_df, diag_kind = 'kde')

"""Semua fitur numerik memiliki korelasi yang kecil dengan energy comsumption, yang terlihat memiliki korelasi yaitu square footage, lalu number of occupants dan appliances used, walaupun lebih kecil, dan average temperature yang korelasinya sangat kecil. Untuk lebih jelas mengevauasi skor korelasinya, gunakan fungsi corr()"""

plt.figure(figsize=(10, 8))
correlation_matrix = combined_df[numerical_features].corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""## Feature Selection

Dari univariate dan multivariate analysis yang telah dilakukan dapat disimpulkan bahwa fitur "Day of Week" dan "Average Temperature" memiliki korelasi yang kecil terhadap Energy Consumption, sehingga kedua fitur tersebut dapat dihapus
"""

selected_df = combined_df.drop(columns=['Day of Week', 'Average Temperature'])
selected_df.head()

"""#Data Preparation

Mempersiapkan data agar sesuai dengan model yang akan dibuat, akan dilakukan encoding untuk fitur kategorikal, data splitting menjadi train dan test, serta standarisasi fitur numerikal

## Encode Fitur Kategorikal

Komputer hanya bisa mengenali angka, maka dari itu perlu dilakukan encoding dari fitur kategorikal menjadi angka. Encoding yang digunakan disini adalah one hot encoding atau mengubah fitur kategorikal menjadi beberapa kolom yang akan berisi 0 atau 1 sesuai dengan nilai asal kolom kategorikal sebelumnya
"""

encoded_df = combined_df.copy()
encoded_df = pd.concat([encoded_df, pd.get_dummies(encoded_df['Building Type'], prefix='Building Type')],axis=1)
encoded_df = pd.concat([encoded_df, pd.get_dummies(encoded_df['Day of Week'], prefix='Day of Week')],axis=1)
encoded_df.drop(['Building Type','Day of Week'], axis=1, inplace=True)
encoded_df.head()

"""## Data Splitting

Memisahkan dataset menjadi data training (untuk melatih model) dan test (untuk menguji model)
"""

from sklearn.model_selection import train_test_split

X = encoded_df.drop(["Energy Consumption"],axis =1)
y = encoded_df["Energy Consumption"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

X_train.head()

"""## Standarisasi

Melakukan standarisasi nilai agar model mudah untuk dilatih. Untuk menghindari kebocoran informasi pada data uji, standarisasi hanya diterapkan pada data latih. Kemudian, pada tahap evaluasi, kita akan melakukan standarisasi pada data uji.
"""

X_train.info()

from sklearn.preprocessing import StandardScaler

numerical_features = ['Square Footage', 'Number of Occupants', 'Appliances Used','Average Temperature']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train[numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(4)

X_train.head()

# Lakukan scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
X_test[numerical_features] = scaler.transform(X_test[numerical_features])

X_test.head()

"""# Model Development

Digunakan model regressi untuk menyelesaikan masalah yang ditentukan. Algoritma yang digunakan untuk membangun model adalah K-Nearest Neighbor REgressor (KNN), Random Forest Regressor (RF), Gradient Boost Regressor (GB), dan XGBoost Regressor. Dibandingkan juga hasil tanpa feature selection dan dengan feature selection.

## Tanpa Feature Selection
"""

#import library
from sklearn.metrics import mean_squared_error
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from xgboost import XGBRegressor

#----Buat model dan prediksi-----
#KNN
knn = KNeighborsRegressor(n_neighbors=5)
knn.fit(X_train, y_train)

#RandomForest
RF = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1)
RF.fit(X_train, y_train)

#GradientBoosting
GB = GradientBoostingRegressor(n_estimators=70, learning_rate=0.2)
GB.fit(X_train, y_train)

#XGBoost
XGB = XGBRegressor(n_estimators=100, learning_rate=0.2, random_state=42)
XGB.fit(X_train, y_train)

"""## Dengan Feature Selection

Pada EDA didapat bahwa Day of Week dan Average Temperature tidak terlalu berkorelasi dengan Energy consumption, maka dari itu kedua fitur tersebut bisa dihapus
"""

X_train_selected = X_train.drop(columns=['Day of Week_Weekday', 'Day of Week_Weekend', 'Average Temperature'])
X_train_selected.head()

X_test_selected = X_test.drop(columns=['Day of Week_Weekday', 'Day of Week_Weekend', 'Average Temperature'])
X_test_selected.head()

#import library
from sklearn.metrics import mean_squared_error
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from xgboost import XGBRegressor

#----Buat model dan prediksi-----
#KNN
knn2 = KNeighborsRegressor(n_neighbors=5)
knn2.fit(X_train_selected, y_train)

#RandomForest
RF2 = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1)
RF2.fit(X_train_selected, y_train)

#GradientBoosting
GB2 = GradientBoostingRegressor(n_estimators=70, learning_rate=0.2)
GB2.fit(X_train_selected, y_train)

#XGBoost
XGB2 = XGBRegressor(n_estimators=100, learning_rate=0.2, random_state=42)
XGB2.fit(X_train_selected, y_train)

"""# Evaluasi Model

Metrik evaluasi yang digunakan pada proyek ini adalah Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), dan R^2 atau R-Squared

## Dengan Feature Selection
"""

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
metrics = pd.DataFrame(columns=['train_mae', 'test_mae', 'train_mse', 'test_mse', 'train_rmse', 'test_rmse', 'train_r2', 'test_r2'],
                       index=['KNN','RF','GradientBoosting','XGBoost'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'GradientBoosting': GB, 'XGBoost': XGB}

# Hitung berbagai metrik untuk masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    # Prediksi untuk data train dan test
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    # MAE (Mean Absolute Error)
    metrics.loc[name, 'train_mae'] = mean_absolute_error(y_true=y_train, y_pred=y_train_pred)
    metrics.loc[name, 'test_mae'] = mean_absolute_error(y_true=y_test, y_pred=y_test_pred)

    # MSE
    metrics.loc[name, 'train_mse'] = mean_squared_error(y_true=y_train, y_pred=y_train_pred)
    metrics.loc[name, 'test_mse'] = mean_squared_error(y_true=y_test, y_pred=y_test_pred)

    # RMSE (Root Mean Squared Error)
    metrics.loc[name, 'train_rmse'] = np.sqrt(mean_squared_error(y_true=y_train, y_pred=y_train_pred))
    metrics.loc[name, 'test_rmse'] = np.sqrt(mean_squared_error(y_true=y_test, y_pred=y_test_pred))

    # R2 (R-squared)
    metrics.loc[name, 'train_r2'] = r2_score(y_true=y_train, y_pred=y_train_pred)
    metrics.loc[name, 'test_r2'] = r2_score(y_true=y_test, y_pred=y_test_pred)

# Panggil metrics
metrics

"""## Dengan Feature Selection"""

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
metrics2 = pd.DataFrame(columns=['train_mae', 'test_mae', 'train_mse', 'test_mse', 'train_rmse', 'test_rmse', 'train_r2', 'test_r2'],
                       index=['KNN','RF','GradientBoosting','XGBoost'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn2, 'RF': RF2, 'GradientBoosting': GB2, 'XGBoost': XGB2}

# Hitung berbagai metrik untuk masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    # Prediksi untuk data train dan test
    y_train_pred = model.predict(X_train_selected)
    y_test_pred = model.predict(X_test_selected)

    # MAE (Mean Absolute Error)
    metrics2.loc[name, 'train_mae'] = mean_absolute_error(y_true=y_train, y_pred=y_train_pred)
    metrics2.loc[name, 'test_mae'] = mean_absolute_error(y_true=y_test, y_pred=y_test_pred)

    # MSE
    metrics2.loc[name, 'train_mse'] = mean_squared_error(y_true=y_train, y_pred=y_train_pred)
    metrics2.loc[name, 'test_mse'] = mean_squared_error(y_true=y_test, y_pred=y_test_pred)

    # RMSE (Root Mean Squared Error)
    metrics2.loc[name, 'train_rmse'] = np.sqrt(mean_squared_error(y_true=y_train, y_pred=y_train_pred))
    metrics2.loc[name, 'test_rmse'] = np.sqrt(mean_squared_error(y_true=y_test, y_pred=y_test_pred))

    # R2 (R-squared)
    metrics2.loc[name, 'train_r2'] = r2_score(y_true=y_train, y_pred=y_train_pred)
    metrics2.loc[name, 'test_r2'] = r2_score(y_true=y_test, y_pred=y_test_pred)

# Panggil metrics2
metrics2

"""# Perbandingan Model

Metrik Evaluasi model tanpa feature selection
"""

metrics

"""Metrik Evaluasi model dengan feature selection"""

metrics2

"""#Kesimpulan

Model yang dibuat mendapat metrik evaluasi yang cukup bagus untuk MAE, MSE, dan RMSE. R-Squared bisa dibilang sangat bagus karena rata-rata di atas 95%. Hal tersebut berlaku untuk semua algoritma yang digunakan.

Hasil model tanpa feature selection secara keseluruhan lebih bagus dibandingkan dengan feature selection walaupun pada EDA ada fitur yang kurang berkorelasi dengan fitur target. Tetapi pada KNN, feature selection membuat hasil metrix nya lebih bagus.
"""